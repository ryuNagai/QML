{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study of following gist code  \n",
    "https://gist.github.com/gyu-don/f7af13e32f9b18010c75ffdb825f97f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from blueqat import Circuit, BlueqatGlobalSetting\n",
    "from blueqat.pauli import I, X, Y, Z\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.Resize([4, 4]),\n",
    "                                   torchvision.transforms.ToTensor()]))\n",
    "test_data = torchvision.datasets.MNIST('./data', train=False,\n",
    "                               transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.Resize([4, 4]),\n",
    "                                   torchvision.transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [i for i, (_, y) in enumerate(train_data) if y in (3, 6)]\n",
    "test_indices = [i for i, (_, y) in enumerate(test_data) if y in (3, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.Subset(train_data, train_indices)\n",
    "test_data = torch.utils.data.Subset(test_data, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fa9d5a871c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data[0][1])\n",
    "plt.imshow(train_data[0][0][0].numpy(), vmin=0, vmax=1); plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From TFQ.\n",
    "def remove_contradicting(dataset):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x, y in dataset:\n",
    "        mapping[tuple(x.flatten().numpy())].add(int(y))\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for x, y in dataset:\n",
    "        labels = mapping[tuple(x.flatten().numpy())]\n",
    "        if len(labels) == 1:\n",
    "            new_x.append(x)\n",
    "            new_y.append(list(labels)[0])\n",
    "        else:\n",
    "            # Throw out images that match more than one label.\n",
    "            pass\n",
    "    \n",
    "    num_3 = sum(1 for value in mapping.values() if 3 in value or 1 in value)\n",
    "    num_6 = sum(1 for value in mapping.values() if 6 in value or -1 in value)\n",
    "    num_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "    print(\"Number of unique images:\", len(mapping.values()))\n",
    "    print(\"Number of 3s: \", num_3)\n",
    "    print(\"Number of 6s: \", num_6)\n",
    "    print(\"Number of contradictory images: \", num_both)\n",
    "    print()\n",
    "    print(\"Initial number of examples: \", len(dataset))\n",
    "    print(\"Remaining non-contradictory examples: \", len(new_x))\n",
    "    \n",
    "    #return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 12049\n",
      "Number of 3s:  6131\n",
      "Number of 6s:  5918\n",
      "Number of contradictory images:  0\n",
      "\n",
      "Initial number of examples:  12049\n",
      "Remaining non-contradictory examples:  12049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12049"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_contradicting(train_data)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.2\n",
    "train_data_bin = torch.utils.data.TensorDataset(torch.cat([x > THRESHOLD for x, _ in train_data]), torch.tensor([1 if y == 3 else -1 for _, y in train_data]))\n",
    "test_data_bin = torch.utils.data.TensorDataset(torch.cat([x > THRESHOLD for x, _ in test_data]), torch.tensor([1 if y == 3 else -1 for _, y in test_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 315\n",
      "Number of 3s:  215\n",
      "Number of 6s:  154\n",
      "Number of contradictory images:  54\n",
      "\n",
      "Initial number of examples:  12049\n",
      "Remaining non-contradictory examples:  4613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12049"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_contradicting(train_data_bin)\n",
    "len(train_data_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_circuit(image, params):\n",
    "    bits = tuple(image.detach().reshape(-1).numpy().nonzero()[0])\n",
    "    c = Circuit()\n",
    "    if bits:\n",
    "        c.x[bits]\n",
    "    c.x[16].h[16]\n",
    "    params = tuple(params.detach().numpy())\n",
    "    for i in range(16):\n",
    "        c.rxx(params[i])[16, i]\n",
    "    for i in range(16):\n",
    "        c.rzz(params[i + 16])[16, i]\n",
    "    c.h[16]\n",
    "    return c\n",
    "\n",
    "model_readout = Z[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_circuit(train_data_bin[0][0], torch.ones(32)).run_with_ibmq(returns='draw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralFunctionWithForwardDifference(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, f, xs, weight):\n",
    "        def f_each(x, weight):\n",
    "            return torch.tensor([f(x, weight) for x in xs], dtype=torch.float64)\n",
    "        ys = f_each(xs, weight)\n",
    "        ctx.save_for_backward(xs, ys, weight)\n",
    "        ctx.f = f_each\n",
    "        return ys\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        xs, ys, weight = ctx.saved_tensors\n",
    "        dw = 0.001\n",
    "        diff = []\n",
    "        weight = weight.detach()\n",
    "        for i in range(len(weight)):\n",
    "            weight[i] += dw\n",
    "            diff.append(torch.sum(grad_output * (ctx.f(xs, weight) - ys)))\n",
    "            weight[i] -= dw\n",
    "        diff = torch.tensor(diff) / dw\n",
    "        #print(\"grad_output\", grad_output, \"end\")\n",
    "        #print(diff)\n",
    "        return None, None, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blueqat.vqe import sparse_expectation\n",
    "\n",
    "class PQC(torch.nn.Module):\n",
    "    def __init__(self, model_circuit, n_params, n_qubits, readout_operators, initial_circuit=None):\n",
    "        super(PQC, self).__init__()\n",
    "        if initial_circuit is None:\n",
    "            initial_circuit = Circuit()\n",
    "        initial_circuit.make_cache()\n",
    "        self.initial_circuit = initial_circuit\n",
    "        self.model_circuit = model_circuit\n",
    "        self.readout_operators = readout_operators\n",
    "        self.sparses = [op.to_matrix(n_qubits=n_qubits, sparse='csc') for op in readout_operators]\n",
    "        self.weight = torch.nn.parameter.Parameter(torch.Tensor(n_params))\n",
    "        torch.nn.init.uniform_(self.weight, 0.0, 2 * np.pi)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        def f(x, weight):\n",
    "            c = self.initial_circuit.copy()\n",
    "            c += self.model_circuit(x, self.weight)\n",
    "            v = c.run()\n",
    "            return [sparse_expectation(sparse, v) for sparse in self.sparses]\n",
    "        return GeneralFunctionWithForwardDifference.apply(f, x, self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HingeLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HingeLoss, self).__init__()\n",
    "        self.loss = torch.nn.MarginRankingLoss(margin=1.)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        zeros = torch.zeros_like(x)\n",
    "        return self.loss(x, zeros, y) # input1, input2, tartget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCELoss, self).__init__()\n",
    "        self.loss = torch.nn.BCELoss()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = (x + 1.0) / 2.0\n",
    "        y = (y + 1.0) / 2.0\n",
    "        return self.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(xs, ys):\n",
    "    xs = xs.detach()\n",
    "    xs = xs > 0.\n",
    "    ys = ys > 0.\n",
    "    return torch.mean((xs == ys).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "try:\n",
    "    from bokeh.io import gridplot\n",
    "except ImportError:\n",
    "    from bokeh.layouts import gridplot\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"186d3b36-1185-4ed9-86b2-12dc543c27f8\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"43383c5a-7b81-4012-8f50-b3217898fd1a\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1016\"},{\"id\":\"1020\"}],\"left\":[{\"id\":\"1017\"}],\"plot_height\":300,\"plot_width\":350,\"renderers\":[{\"id\":\"1038\"},{\"id\":\"1043\"}],\"title\":{\"id\":\"1003\"},\"toolbar\":{\"id\":\"1028\"},\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1027\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1051\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"red\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1037\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1052\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"source\":{\"id\":\"1035\"}},\"id\":\"1039\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"red\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1036\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"1040\"}},\"id\":\"1044\",\"type\":\"CDSView\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"blue\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1042\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1053\",\"type\":\"Selection\"},{\"attributes\":{\"line_color\":\"blue\",\"line_width\":2,\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1041\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1054\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"x\":[],\"y\":[]},\"selected\":{\"id\":\"1053\"},\"selection_policy\":{\"id\":\"1054\"}},\"id\":\"1040\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"formatter\":{\"id\":\"1048\"},\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data_source\":{\"id\":\"1040\"},\"glyph\":{\"id\":\"1041\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1042\"},\"selection_glyph\":null,\"view\":{\"id\":\"1044\"}},\"id\":\"1043\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"text\":\"Loss\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{\"data\":{\"x\":[],\"y\":[]},\"selected\":{\"id\":\"1051\"},\"selection_policy\":{\"id\":\"1052\"}},\"id\":\"1035\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1027\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"data_source\":{\"id\":\"1035\"},\"glyph\":{\"id\":\"1036\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1037\"},\"selection_glyph\":null,\"view\":{\"id\":\"1039\"}},\"id\":\"1038\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"end\":378,\"start\":-1},\"id\":\"1005\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"ticker\":null},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"1046\"},\"ticker\":{\"id\":\"1018\"}},\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1017\"},\"dimension\":1,\"ticker\":null},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"}]},\"id\":\"1028\",\"type\":\"Toolbar\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"43383c5a-7b81-4012-8f50-b3217898fd1a\",\"notebook_comms_target\":\"1055\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"186d3b36-1185-4ed9-86b2-12dc543c27f8\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 3\n",
    "batch_size = 32\n",
    "x_range_max = len(train_data_bin) // batch_size + 2\n",
    "\n",
    "p = figure(title=\"Loss\", plot_height=300, plot_width=350, y_range=(0, 1.0), x_range=(-1, x_range_max))\n",
    "r_train = p.line([], [], color=\"red\", line_width=2)\n",
    "r_test = p.line([], [], color=\"blue\", line_width=2)\n",
    "show(p, notebook_handle=True) \n",
    "\n",
    "def update(epoch, d1, d2):\n",
    "    print(epoch, d1, d2)\n",
    "    r_train.data_source.stream({'x': [epoch], 'y': [d1]})\n",
    "    r_test.data_source.stream({'x': [epoch], 'y': [d2]})\n",
    "    push_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0132359266281128 0.375\n",
      "1 1.0281637907028198 0.1875\n",
      "2 0.9980336427688599 0.5625\n",
      "3 1.01261305809021 0.40625\n",
      "4 0.999859094619751 0.5625\n",
      "5 1.007081389427185 0.375\n",
      "6 1.003542184829712 0.40625\n",
      "7 1.000455379486084 0.53125\n",
      "8 1.0056874752044678 0.40625\n",
      "9 0.9969677925109863 0.53125\n",
      "10 0.9974995851516724 0.46875\n",
      "11 1.0001001358032227 0.4375\n",
      "12 1.0000580549240112 0.46875\n",
      "13 1.0028553009033203 0.46875\n",
      "14 1.0035182237625122 0.4375\n",
      "15 0.997887909412384 0.59375\n",
      "16 0.9878233671188354 0.75\n",
      "17 0.9938411712646484 0.625\n",
      "18 0.9942618608474731 0.6875\n",
      "19 0.9932988882064819 0.59375\n",
      "20 0.9893931746482849 0.65625\n",
      "21 1.007421851158142 0.40625\n",
      "22 0.9990012049674988 0.46875\n",
      "23 0.9969602823257446 0.53125\n",
      "24 1.0023548603057861 0.46875\n",
      "25 0.9943318963050842 0.65625\n",
      "26 1.0001386404037476 0.5\n",
      "27 0.9916216731071472 0.625\n",
      "28 0.9992318153381348 0.53125\n",
      "29 1.0067135095596313 0.4375\n",
      "30 0.9954574108123779 0.5625\n",
      "31 0.9976319670677185 0.5\n",
      "32 1.0011305809020996 0.5625\n",
      "33 0.9962366819381714 0.53125\n",
      "34 0.983023464679718 0.8125\n",
      "35 1.0002154111862183 0.5\n",
      "36 0.9915422797203064 0.65625\n",
      "37 0.9918657541275024 0.59375\n",
      "38 0.9927889108657837 0.53125\n",
      "39 0.9870456457138062 0.65625\n",
      "40 1.0015442371368408 0.46875\n",
      "41 0.9915729761123657 0.59375\n",
      "42 0.9790740609169006 0.65625\n",
      "43 1.0080854892730713 0.4375\n",
      "44 1.004163384437561 0.46875\n",
      "45 0.9750123023986816 0.71875\n",
      "46 0.9759577512741089 0.65625\n",
      "47 0.98444664478302 0.625\n",
      "48 0.9982737302780151 0.5625\n",
      "49 0.9962785243988037 0.59375\n",
      "50 0.979841411113739 0.59375\n",
      "51 0.9713115096092224 0.6875\n",
      "52 0.9736886620521545 0.59375\n",
      "53 0.9912894368171692 0.5\n",
      "54 0.9897723197937012 0.5\n",
      "55 0.9813751578330994 0.46875\n",
      "56 0.9700786471366882 0.5625\n",
      "57 0.9976628422737122 0.5\n",
      "58 0.9657840132713318 0.5625\n",
      "59 0.9718567728996277 0.59375\n",
      "60 0.9338849782943726 0.78125\n",
      "61 0.9674607515335083 0.5625\n",
      "62 0.9642500281333923 0.46875\n",
      "63 0.9787774682044983 0.5625\n",
      "64 0.954776406288147 0.65625\n",
      "65 0.9914007186889648 0.46875\n",
      "66 0.9230697154998779 0.6875\n",
      "67 0.8680261969566345 0.78125\n",
      "68 0.8850173950195312 0.75\n",
      "69 0.9233243465423584 0.59375\n",
      "70 0.9836287498474121 0.5\n",
      "71 0.8035354018211365 0.8125\n",
      "72 0.8505423069000244 0.75\n",
      "73 0.8234558701515198 0.71875\n",
      "74 0.8911254405975342 0.59375\n",
      "75 0.9583763480186462 0.5\n",
      "76 0.8264567255973816 0.71875\n",
      "77 0.838327169418335 0.6875\n",
      "78 0.9316797256469727 0.5\n",
      "79 0.942416787147522 0.5\n",
      "80 0.8804874420166016 0.53125\n",
      "81 0.8933306336402893 0.5\n",
      "82 0.9093166589736938 0.5\n",
      "83 1.012535810470581 0.34375\n",
      "84 0.9484380483627319 0.46875\n",
      "85 0.6688294410705566 0.75\n",
      "86 0.6146824955940247 0.75\n",
      "87 0.7304474115371704 0.625\n",
      "88 0.7516496181488037 0.65625\n",
      "89 0.8770186901092529 0.53125\n",
      "90 0.8489930629730225 0.5625\n",
      "91 0.7350617051124573 0.625\n",
      "92 0.6617076992988586 0.75\n",
      "93 0.5199723839759827 0.84375\n",
      "94 0.7393444180488586 0.5625\n",
      "95 0.817067563533783 0.59375\n",
      "96 0.46074676513671875 0.90625\n",
      "97 0.5050960779190063 0.84375\n",
      "98 0.5060281753540039 0.84375\n",
      "99 0.7017428278923035 0.84375\n",
      "100 0.4122825264930725 0.90625\n",
      "101 0.7438348531723022 0.75\n",
      "102 0.4596680998802185 0.875\n",
      "103 0.7042990922927856 0.6875\n",
      "104 0.60196453332901 0.75\n",
      "105 0.5908542275428772 0.75\n",
      "106 0.5710552930831909 0.71875\n",
      "107 0.6862964034080505 0.6875\n",
      "108 0.32969745993614197 0.90625\n",
      "109 0.4065002501010895 0.875\n",
      "110 0.4008602499961853 0.90625\n",
      "111 0.46128350496292114 0.8125\n",
      "112 0.5401710867881775 0.75\n",
      "113 0.5689719915390015 0.75\n",
      "114 0.47363483905792236 0.78125\n",
      "115 0.46098509430885315 0.8125\n",
      "116 0.3327087163925171 0.90625\n",
      "117 0.505220890045166 0.78125\n",
      "118 0.6086164712905884 0.71875\n",
      "119 0.6961581707000732 0.65625\n",
      "120 0.5365641713142395 0.78125\n",
      "121 0.4899805188179016 0.78125\n",
      "122 0.28483736515045166 0.90625\n",
      "123 0.6500255465507507 0.75\n",
      "124 0.3392053246498108 0.875\n",
      "125 0.3768894076347351 0.84375\n",
      "126 0.3923076391220093 0.8125\n",
      "127 0.24717304110527039 0.9375\n",
      "128 0.44896817207336426 0.8125\n",
      "129 0.568874716758728 0.71875\n",
      "130 0.6230484843254089 0.6875\n",
      "131 0.4263223111629486 0.78125\n",
      "132 0.2722364664077759 0.90625\n",
      "133 0.4791693091392517 0.78125\n",
      "134 0.6448643803596497 0.65625\n",
      "135 0.3696550726890564 0.84375\n",
      "136 0.3735240697860718 0.84375\n",
      "137 0.308047354221344 0.875\n",
      "138 0.3990953862667084 0.8125\n",
      "139 0.6282169818878174 0.6875\n",
      "140 0.43667998909950256 0.78125\n",
      "141 0.37802624702453613 0.84375\n",
      "142 0.1747712343931198 0.9375\n",
      "143 0.6155626773834229 0.6875\n",
      "144 0.33049044013023376 0.84375\n",
      "145 0.47998255491256714 0.78125\n",
      "146 0.7017582654953003 0.65625\n",
      "147 0.8468829393386841 0.5625\n",
      "148 0.23974201083183289 0.90625\n",
      "149 0.44202226400375366 0.78125\n",
      "150 0.5700564980506897 0.71875\n",
      "151 0.2994888722896576 0.84375\n",
      "152 0.548822283744812 0.71875\n",
      "153 0.25284940004348755 0.90625\n",
      "154 0.6067029237747192 0.71875\n",
      "155 0.529089093208313 0.75\n",
      "156 0.47589725255966187 0.75\n",
      "157 0.3799324035644531 0.8125\n",
      "158 0.4434424340724945 0.78125\n",
      "159 0.3844841718673706 0.8125\n",
      "160 0.5570468306541443 0.71875\n",
      "161 0.3769444227218628 0.84375\n",
      "162 0.28883853554725647 0.875\n",
      "163 0.3772895932197571 0.8125\n",
      "164 0.5595113635063171 0.71875\n",
      "165 0.29579421877861023 0.875\n",
      "166 0.3756931722164154 0.8125\n",
      "167 0.3741377294063568 0.8125\n",
      "168 0.5597120523452759 0.71875\n",
      "169 0.40986883640289307 0.8125\n",
      "170 0.39163434505462646 0.8125\n",
      "171 0.14894665777683258 0.9375\n",
      "172 0.3576419949531555 0.84375\n",
      "173 0.7210185527801514 0.625\n",
      "174 0.5429363250732422 0.71875\n",
      "175 0.31031590700149536 0.84375\n",
      "176 0.35679081082344055 0.8125\n",
      "177 0.4698196351528168 0.78125\n",
      "178 0.5017350316047668 0.75\n",
      "179 0.3689652979373932 0.8125\n",
      "180 0.33039379119873047 0.84375\n",
      "181 0.25210121273994446 0.875\n",
      "182 0.3495163917541504 0.84375\n",
      "183 0.38332343101501465 0.8125\n",
      "184 0.2759183645248413 0.875\n",
      "185 0.5393911600112915 0.71875\n",
      "186 0.2746177911758423 0.875\n",
      "187 0.4120768904685974 0.78125\n",
      "188 0.26300927996635437 0.875\n",
      "189 0.30653488636016846 0.84375\n",
      "190 0.2607228457927704 0.875\n",
      "191 0.3166733980178833 0.84375\n",
      "192 0.45141738653182983 0.78125\n",
      "193 0.4314526915550232 0.78125\n",
      "194 0.36209723353385925 0.8125\n",
      "195 0.5063669085502625 0.75\n",
      "196 0.26659446954727173 0.875\n",
      "197 0.20769977569580078 0.90625\n",
      "198 0.29213470220565796 0.875\n",
      "199 0.5287668704986572 0.75\n",
      "200 0.3682730793952942 0.84375\n",
      "201 0.24287548661231995 0.875\n",
      "202 0.3613746166229248 0.8125\n",
      "203 0.7380279302597046 0.59375\n",
      "204 0.46678221225738525 0.75\n",
      "205 0.4229743778705597 0.78125\n",
      "206 0.3252640962600708 0.84375\n",
      "207 0.31639885902404785 0.84375\n",
      "208 0.35001540184020996 0.8125\n",
      "209 0.3641994893550873 0.8125\n",
      "210 0.5468353629112244 0.71875\n",
      "211 0.7819839715957642 0.59375\n",
      "212 0.5009929537773132 0.75\n",
      "213 0.3724897503852844 0.78125\n",
      "214 0.03002777509391308 1.0\n",
      "215 0.19618430733680725 0.90625\n",
      "216 0.5374996662139893 0.71875\n",
      "217 0.5257670879364014 0.71875\n",
      "218 0.5011531114578247 0.75\n",
      "219 0.6754517555236816 0.65625\n",
      "220 0.4282280206680298 0.78125\n",
      "221 0.4083998203277588 0.78125\n",
      "222 0.2744990587234497 0.875\n",
      "223 0.4117327928543091 0.78125\n",
      "224 0.5223314166069031 0.71875\n",
      "225 0.3898982107639313 0.78125\n",
      "226 0.46673235297203064 0.71875\n",
      "227 0.3897871971130371 0.8125\n",
      "228 0.35722780227661133 0.84375\n",
      "229 0.3719443082809448 0.8125\n",
      "230 0.3086080849170685 0.84375\n",
      "231 0.27603083848953247 0.84375\n",
      "232 0.3280367851257324 0.84375\n",
      "233 0.4222080707550049 0.78125\n",
      "234 0.611265242099762 0.65625\n",
      "235 0.15749293565750122 0.9375\n",
      "236 0.5275156497955322 0.71875\n",
      "237 0.5546908974647522 0.6875\n",
      "238 0.3980385661125183 0.8125\n",
      "239 0.5030668377876282 0.75\n",
      "240 0.41426295042037964 0.8125\n",
      "241 0.6328969597816467 0.71875\n",
      "242 0.359669953584671 0.84375\n",
      "243 0.4204082489013672 0.8125\n",
      "244 0.26075947284698486 0.875\n",
      "245 0.34724587202072144 0.84375\n",
      "246 0.15748676657676697 0.9375\n",
      "247 0.3821776509284973 0.84375\n",
      "248 0.4293938875198364 0.8125\n",
      "249 0.5415374636650085 0.71875\n",
      "250 0.6235138177871704 0.75\n",
      "251 0.2555563449859619 0.9375\n",
      "252 0.4571479558944702 0.8125\n",
      "253 0.4409942626953125 0.84375\n",
      "254 0.4061555862426758 0.8125\n",
      "255 0.541917622089386 0.71875\n",
      "256 0.3396841287612915 0.90625\n",
      "257 0.2003626972436905 0.9375\n",
      "258 0.5238025784492493 0.8125\n",
      "259 0.4061819314956665 0.84375\n",
      "260 0.4772738218307495 0.75\n",
      "261 0.6003093123435974 0.6875\n",
      "262 0.4701635241508484 0.8125\n",
      "263 0.39597874879837036 0.90625\n",
      "264 0.29839569330215454 0.9375\n",
      "265 0.3123317360877991 0.875\n",
      "266 0.49882012605667114 0.8125\n",
      "267 0.19192107021808624 0.96875\n",
      "268 0.3666212856769562 0.875\n",
      "269 0.3461810350418091 0.84375\n",
      "270 0.2678074240684509 0.90625\n",
      "271 0.34728938341140747 0.90625\n",
      "272 0.5686913728713989 0.75\n",
      "273 0.20306481420993805 0.9375\n",
      "274 0.2737116515636444 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 0.44268032908439636 0.78125\n",
      "276 0.4813532829284668 0.75\n",
      "277 0.3406112492084503 0.875\n",
      "278 0.3619425892829895 0.84375\n",
      "279 0.4496346712112427 0.8125\n",
      "280 0.24728572368621826 0.90625\n",
      "281 0.441173791885376 0.8125\n",
      "282 0.2750810980796814 0.875\n",
      "283 0.41564229130744934 0.78125\n",
      "284 0.40604138374328613 0.8125\n",
      "285 0.3808736801147461 0.84375\n",
      "286 0.46694034337997437 0.8125\n",
      "287 0.483035683631897 0.78125\n",
      "288 0.37861889600753784 0.875\n",
      "289 0.4497416019439697 0.78125\n",
      "290 0.3764769732952118 0.84375\n",
      "291 0.3494316339492798 0.875\n",
      "292 0.499079167842865 0.78125\n",
      "293 0.4907575249671936 0.78125\n",
      "294 0.6146500706672668 0.65625\n",
      "295 0.3988613784313202 0.875\n",
      "296 0.42279890179634094 0.8125\n",
      "297 0.4320105016231537 0.8125\n",
      "298 0.35263338685035706 0.84375\n",
      "299 0.386883020401001 0.84375\n",
      "300 0.2210882157087326 0.9375\n",
      "301 0.2987397313117981 0.9375\n",
      "302 0.3189532160758972 0.875\n",
      "303 0.33170369267463684 0.8125\n",
      "304 0.23420622944831848 0.90625\n",
      "305 0.40876251459121704 0.8125\n",
      "306 0.48278480768203735 0.84375\n",
      "307 0.36905333399772644 0.84375\n",
      "308 0.636509895324707 0.65625\n",
      "309 0.2571823000907898 0.9375\n",
      "310 0.44567155838012695 0.78125\n",
      "311 0.40362411737442017 0.875\n",
      "312 0.4408819079399109 0.8125\n",
      "313 0.4117620587348938 0.90625\n",
      "314 0.2650490999221802 0.90625\n",
      "315 0.32936590909957886 0.90625\n",
      "316 0.3788379728794098 0.90625\n",
      "317 0.3344377875328064 0.90625\n",
      "318 0.4346110224723816 0.78125\n",
      "319 0.3268841505050659 0.875\n",
      "320 0.31787940859794617 0.875\n",
      "321 0.5428339838981628 0.8125\n",
      "322 0.5101020336151123 0.8125\n",
      "323 0.4028562903404236 0.8125\n",
      "324 0.15680378675460815 0.96875\n",
      "325 0.491843581199646 0.78125\n",
      "326 0.4713754653930664 0.84375\n",
      "327 0.33060917258262634 0.875\n",
      "328 0.3066602349281311 0.875\n",
      "329 0.35810530185699463 0.875\n",
      "330 0.4603976011276245 0.84375\n",
      "331 0.4956890344619751 0.78125\n",
      "332 0.3753032684326172 0.84375\n",
      "333 0.32882681488990784 0.90625\n",
      "334 0.42080119252204895 0.8125\n",
      "335 0.4318355619907379 0.8125\n",
      "336 0.2566390037536621 0.90625\n",
      "337 0.6139304637908936 0.6875\n",
      "338 0.35075217485427856 0.84375\n",
      "339 0.3151843249797821 0.90625\n",
      "340 0.404913991689682 0.84375\n",
      "341 0.535070538520813 0.78125\n",
      "342 0.20686030387878418 0.96875\n",
      "343 0.40779584646224976 0.84375\n",
      "344 0.5417115688323975 0.75\n",
      "345 0.41043031215667725 0.78125\n",
      "346 0.30997687578201294 0.84375\n",
      "347 0.3826119899749756 0.84375\n",
      "348 0.39378198981285095 0.8125\n",
      "349 0.29039886593818665 0.90625\n",
      "350 0.5861725807189941 0.71875\n",
      "351 0.50650554895401 0.78125\n",
      "352 0.29904061555862427 0.875\n",
      "353 0.39121174812316895 0.84375\n",
      "354 0.34376752376556396 0.875\n",
      "355 0.47527042031288147 0.8125\n",
      "356 0.4829641580581665 0.78125\n",
      "357 0.41019052267074585 0.84375\n",
      "358 0.4684455990791321 0.8125\n",
      "359 0.4889874756336212 0.84375\n",
      "360 0.3772919476032257 0.90625\n",
      "361 0.2977830171585083 0.9375\n",
      "362 0.3415602147579193 0.90625\n",
      "363 0.4939664900302887 0.8125\n",
      "364 0.3951679766178131 0.90625\n",
      "365 0.4046858549118042 0.875\n",
      "366 0.40707704424858093 0.8125\n",
      "367 0.443195104598999 0.84375\n",
      "368 0.4905445873737335 0.8125\n",
      "369 0.2685662508010864 0.90625\n",
      "370 0.4221351742744446 0.8125\n",
      "371 0.3591773808002472 0.875\n",
      "372 0.4522494077682495 0.84375\n",
      "373 0.3936654329299927 0.84375\n",
      "374 0.3179702162742615 0.90625\n",
      "375 0.2259851098060608 0.9375\n",
      "376 0.5869354009628296 0.6470588445663452\n",
      "0 0.5509682297706604 0.36976975202560425\n",
      "377 0.4355827867984772 0.8125\n",
      "378 0.3820391893386841 0.84375\n",
      "379 0.4238624572753906 0.8125\n",
      "380 0.245517760515213 0.96875\n",
      "381 0.2965262532234192 0.90625\n",
      "382 0.3392598032951355 0.84375\n",
      "383 0.31065550446510315 0.875\n",
      "384 0.3447323143482208 0.875\n",
      "385 0.4004131555557251 0.84375\n",
      "386 0.37151652574539185 0.875\n",
      "387 0.3604673147201538 0.90625\n",
      "388 0.38269829750061035 0.90625\n",
      "389 0.5153681635856628 0.75\n",
      "390 0.3372165262699127 0.90625\n",
      "391 0.4038771688938141 0.84375\n",
      "392 0.37250474095344543 0.875\n",
      "393 0.4634295701980591 0.8125\n",
      "394 0.3971058130264282 0.875\n",
      "395 0.3487989902496338 0.96875\n",
      "396 0.4248504638671875 0.875\n",
      "397 0.3986656069755554 0.84375\n",
      "398 0.41009190678596497 0.84375\n",
      "399 0.5245727300643921 0.8125\n",
      "400 0.2149246484041214 0.96875\n",
      "401 0.3549661934375763 0.875\n",
      "402 0.5817719101905823 0.71875\n",
      "403 0.41926485300064087 0.90625\n",
      "404 0.39485421776771545 0.875\n",
      "405 0.38499683141708374 0.875\n",
      "406 0.34721216559410095 0.90625\n",
      "407 0.3984582722187042 0.90625\n",
      "408 0.42800554633140564 0.84375\n",
      "409 0.4738420844078064 0.8125\n",
      "410 0.289890855550766 0.90625\n",
      "411 0.3409021496772766 0.9375\n",
      "412 0.392347514629364 0.84375\n",
      "413 0.3772621750831604 0.8125\n",
      "414 0.29152601957321167 0.9375\n",
      "415 0.4345288574695587 0.875\n",
      "416 0.3440479636192322 0.9375\n",
      "417 0.4295867681503296 0.84375\n",
      "418 0.2678748369216919 0.90625\n",
      "419 0.18310479819774628 1.0\n",
      "420 0.3113659620285034 0.9375\n",
      "421 0.3319094181060791 0.90625\n",
      "422 0.35156524181365967 0.875\n",
      "423 0.3023934066295624 0.90625\n",
      "424 0.4742237329483032 0.84375\n",
      "425 0.31493133306503296 0.875\n",
      "426 0.5384568572044373 0.75\n",
      "427 0.3122985363006592 0.90625\n",
      "428 0.20653405785560608 0.96875\n",
      "429 0.569153368473053 0.6875\n",
      "430 0.3924310505390167 0.84375\n",
      "431 0.3124198317527771 0.875\n",
      "432 0.3698652982711792 0.84375\n",
      "433 0.2792954742908478 0.90625\n",
      "434 0.1858280748128891 0.96875\n",
      "435 0.3318677544593811 0.875\n",
      "436 0.3602651357650757 0.84375\n",
      "437 0.34534600377082825 0.84375\n",
      "438 0.28925856947898865 0.875\n",
      "439 0.35077181458473206 0.84375\n",
      "440 0.1943221390247345 0.96875\n",
      "441 0.3961000442504883 0.875\n",
      "442 0.4167957603931427 0.84375\n",
      "443 0.32121267914772034 0.90625\n",
      "444 0.5426751971244812 0.75\n",
      "445 0.3434194326400757 0.90625\n",
      "446 0.43424880504608154 0.8125\n",
      "447 0.2918972671031952 0.9375\n",
      "448 0.4471031129360199 0.8125\n",
      "449 0.2405860424041748 0.9375\n",
      "450 0.4274784326553345 0.78125\n",
      "451 0.3629765510559082 0.875\n",
      "452 0.4356689751148224 0.78125\n",
      "453 0.49514082074165344 0.78125\n",
      "454 0.45257192850112915 0.8125\n",
      "455 0.4649362564086914 0.75\n",
      "456 0.531243622303009 0.75\n",
      "457 0.4401366114616394 0.78125\n",
      "458 0.4875335693359375 0.75\n",
      "459 0.3421041965484619 0.84375\n",
      "460 0.3171866536140442 0.90625\n",
      "461 0.321486234664917 0.90625\n",
      "462 0.4837954044342041 0.8125\n",
      "463 0.27802959084510803 0.9375\n",
      "464 0.40450140833854675 0.84375\n",
      "465 0.41312676668167114 0.84375\n",
      "466 0.5674371123313904 0.78125\n",
      "467 0.35995039343833923 0.90625\n",
      "468 0.5042377710342407 0.78125\n",
      "469 0.2603150010108948 0.9375\n",
      "470 0.3184830844402313 0.875\n",
      "471 0.28449925780296326 0.9375\n",
      "472 0.241768941283226 0.96875\n",
      "473 0.39471277594566345 0.84375\n",
      "474 0.512894332408905 0.78125\n",
      "475 0.3603927791118622 0.875\n",
      "476 0.3686310052871704 0.84375\n",
      "477 0.2521534860134125 0.90625\n",
      "478 0.470126748085022 0.875\n",
      "479 0.2655861973762512 0.96875\n",
      "480 0.4420638084411621 0.84375\n",
      "481 0.23665164411067963 0.9375\n",
      "482 0.14548030495643616 1.0\n",
      "483 0.4307014048099518 0.8125\n",
      "484 0.2754564881324768 0.9375\n",
      "485 0.30826425552368164 0.90625\n",
      "486 0.37235140800476074 0.875\n",
      "487 0.3271908462047577 0.9375\n",
      "488 0.521091103553772 0.8125\n",
      "489 0.3634021580219269 0.875\n",
      "490 0.2528855800628662 0.9375\n",
      "491 0.28234341740608215 0.875\n",
      "492 0.25536084175109863 0.90625\n",
      "493 0.3802003562450409 0.84375\n",
      "494 0.38784122467041016 0.875\n",
      "495 0.5012490153312683 0.8125\n",
      "496 0.3269273638725281 0.875\n",
      "497 0.36209219694137573 0.875\n",
      "498 0.3356247544288635 0.96875\n",
      "499 0.2883263826370239 0.9375\n",
      "500 0.3305929899215698 0.90625\n",
      "501 0.3132612407207489 0.9375\n",
      "502 0.24074755609035492 0.875\n",
      "503 0.4856911897659302 0.8125\n",
      "504 0.563075602054596 0.71875\n",
      "505 0.40375545620918274 0.84375\n",
      "506 0.5539315938949585 0.78125\n",
      "507 0.4495312571525574 0.78125\n",
      "508 0.5202358961105347 0.78125\n",
      "509 0.4813786745071411 0.78125\n",
      "510 0.3030563294887543 0.90625\n",
      "511 0.2535289227962494 0.90625\n",
      "512 0.38125908374786377 0.84375\n",
      "513 0.3849661946296692 0.84375\n",
      "514 0.23132415115833282 0.96875\n",
      "515 0.25458189845085144 0.90625\n",
      "516 0.6286728978157043 0.71875\n",
      "517 0.3517525792121887 0.9375\n",
      "518 0.33156150579452515 0.90625\n",
      "519 0.2593812048435211 0.90625\n",
      "520 0.287331759929657 0.9375\n",
      "521 0.44480082392692566 0.8125\n",
      "522 0.5011034607887268 0.71875\n",
      "523 0.38209277391433716 0.875\n",
      "524 0.3561641573905945 0.875\n",
      "525 0.375235378742218 0.90625\n",
      "526 0.2439521998167038 0.90625\n",
      "527 0.24179434776306152 0.96875\n",
      "528 0.37561142444610596 0.90625\n",
      "529 0.4227496385574341 0.875\n",
      "530 0.2434621900320053 0.9375\n",
      "531 0.4571910798549652 0.84375\n",
      "532 0.27489179372787476 0.9375\n",
      "533 0.4966875910758972 0.75\n",
      "534 0.5260958075523376 0.75\n",
      "535 0.40641605854034424 0.8125\n",
      "536 0.5251413583755493 0.78125\n",
      "537 0.3311845660209656 0.84375\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "python_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2f1e5ab94843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/Blueqat/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/Blueqat/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: python_error"
     ]
    }
   ],
   "source": [
    "from blueqat import BlueqatGlobalSetting\n",
    "BlueqatGlobalSetting.set_default_backend('numba')\n",
    "\n",
    "model = PQC(model_circuit, 32, 17, [model_readout])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = HingeLoss()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data_bin, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data_bin)\n",
    "\n",
    "losshist_train = []; losshist_test = []\n",
    "i = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for im, label in train_loader: # label: 3 is 1, 6 is -1\n",
    "        out = model(im)\n",
    "        out = out.reshape(-1).float()\n",
    "        loss = criterion(out, label)\n",
    "        losses.append(loss.detach())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = accuracy(out, label)\n",
    "        update(i, float(torch.mean(loss.detach()).item()), float(acc.item()))\n",
    "        i += 1\n",
    "    losshist_train.append(torch.mean(torch.tensor(losses)).item())\n",
    "    \n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for im, label in test_loader:\n",
    "        out = model(im)\n",
    "        out = out.reshape(-1).float()\n",
    "        loss = criterion(out, label)\n",
    "        losses.append(loss.detach())\n",
    "    losshist_test.append(torch.mean(torch.tensor(losses)).item())\n",
    "    \n",
    "    update(epoch, losshist_train[-1], losshist_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losshist_train, label='train')\n",
    "plt.plot(losshist_test, label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist.pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result: 1576/1968 (80.08130081300813 %)\n"
     ]
    }
   ],
   "source": [
    "count = 0; tot = 0\n",
    "for im, label in test_loader:\n",
    "    model.eval()\n",
    "    out = model(im)\n",
    "    if (out.item() > 0.5) == (label.item() > 0.5):\n",
    "        count += 1\n",
    "    tot += 1\n",
    "print(f'Test result: {count}/{tot} ({100 * count / tot} %)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another test\n",
    "\n",
    "In above test, results such that {out=0.2, label=-1} is judged as validly predicted.  \n",
    "However it should be judged as incorrect, so I made another test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result: 1697/1968 (86.22967479674797 %)\n"
     ]
    }
   ],
   "source": [
    "count = 0; tot = 0\n",
    "THRESHOLD = 0.\n",
    "for im, label in test_loader:\n",
    "    model.eval()\n",
    "    out = model(im)\n",
    "    if (out.item() > THRESHOLD) and (label.item() > THRESHOLD):\n",
    "        count += 1\n",
    "    elif (out.item() < -1.0 * THRESHOLD) and (label.item() < -1.0 * THRESHOLD):\n",
    "        count += 1\n",
    "    tot += 1\n",
    "print(f'Test result: {count}/{tot} ({100 * count / tot} %)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.functional.relu\n",
    "tanh = torch.nn.functional.tanh\n",
    "class ClassicalModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(16, 8)\n",
    "        self.fc2 = torch.nn.Linear(8, 4)\n",
    "        self.fc3 = torch.nn.Linear(4, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 16)\n",
    "        x = relu(self.fc1(x.float()))\n",
    "        x = relu(self.fc2(x))\n",
    "        x = tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "c_batch_size = 32\n",
    "x_range_max = epochs + 1\n",
    "\n",
    "p = figure(title=\"Loss\", plot_height=300, plot_width=350, y_range=(0, 1.0), x_range=(-1, x_range_max))\n",
    "r_train = p.line([], [], color=\"red\", line_width=2)\n",
    "r_test = p.line([], [], color=\"blue\", line_width=2)\n",
    "show(p, notebook_handle=True) \n",
    "\n",
    "def update(epoch, d1, d2):\n",
    "    print(epoch, d1, d2)\n",
    "    r_train.data_source.stream({'x': [epoch], 'y': [d1]})\n",
    "    r_test.data_source.stream({'x': [epoch], 'y': [d2]})\n",
    "    push_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.functional.relu\n",
    "tanh = torch.nn.functional.tanh\n",
    "class TinyClassicalModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(16, 2)\n",
    "        self.fc2 = torch.nn.Linear(2, 1)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 16)\n",
    "        x = relu(self.fc1(x.float()))\n",
    "        x = tanh(self.fc2(x.float()))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_model = TinyClassicalModel()\n",
    "sum(p.numel() for p in tiny_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "c_batch_size = 32\n",
    "x_range_max = epochs + 1\n",
    "\n",
    "p = figure(title=\"Loss\", plot_height=300, plot_width=350, y_range=(0, 1.0), x_range=(-1, x_range_max))\n",
    "r_train = p.line([], [], color=\"red\", line_width=2)\n",
    "r_test = p.line([], [], color=\"blue\", line_width=2)\n",
    "show(p, notebook_handle=True) \n",
    "\n",
    "def update(epoch, d1, d2):\n",
    "    print(epoch, d1, d2)\n",
    "    r_train.data_source.stream({'x': [epoch], 'y': [d1]})\n",
    "    r_test.data_source.stream({'x': [epoch], 'y': [d2]})\n",
    "    push_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(tiny_model.parameters(), lr=0.02)\n",
    "criterion = HingeLoss()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data_bin, batch_size=c_batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data_bin)\n",
    "\n",
    "losshist_train = []; losshist_test = []\n",
    "i = 0\n",
    "for epoch in range(epochs):\n",
    "    tiny_model.train()\n",
    "    losses = []; acces = []\n",
    "    for im, label in train_loader:\n",
    "        out = tiny_model(im)\n",
    "        #print(out)\n",
    "        loss = criterion(out.reshape(-1), label)\n",
    "        losses.append(float(loss.detach()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = accuracy(out.reshape(-1), label)\n",
    "        acces.append(float(acc))\n",
    "        i += 1\n",
    "    update(epoch, float(torch.mean(torch.tensor(losses))),\\\n",
    "           float(torch.mean(torch.tensor(acces))))\n",
    "    losshist_train.append(torch.mean(torch.tensor(losses)).item())\n",
    "    \n",
    "    tiny_model.eval()\n",
    "    losses = []\n",
    "    for im, label in test_loader:\n",
    "        out = tiny_model(im)\n",
    "        loss = criterion(out.reshape(-1), label)\n",
    "        losses.append(loss.detach())\n",
    "    losshist_test.append(torch.mean(torch.tensor(losses)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0; tot = 0\n",
    "for im, label in test_loader:\n",
    "    tiny_model.eval()\n",
    "    out = tiny_model(im)\n",
    "    if (out.item() > 0.5) == (label.item() > 0.5):\n",
    "        count += 1\n",
    "    tot += 1\n",
    "print(f'Test result: {count}/{tot} ({100 * count / tot} %)')"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
